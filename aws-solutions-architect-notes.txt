4:01 PM 6/19/2019
start

7:27 AM 6/20/2019

iam - identity access management
iot - internet of things
arn - amazon resource names

global infrastructure
availability zone is a data center. its a facility where there are servers, SANs, switches, load balancer, etc. several data centers that are close together can be a single availability zone. perhaps a few miles within each others. 

a region is a geographical area that contains two or more availability zones. london, oregon, sydeny, tokyo etc. 

edge locations are end points for aws which are used for caching content. typically this consists of cloudfront, amazon's CDN (content delivery network). there are always more edge locations than regions. 

route 53 is amazon's dns service

vpc is virtual private cloud - virtual data center

things needed for solutions architect exam - 
aws global infrastructure
compute
storage
databases
migration & transfer
network & content delivery
management & governance
machine learning
analytics
security, identity & compliance
desktop & app streaming

these are the core services needed - 

aws global infrastructure
compute
storage
databases
network & content delivery
security, identity & compliance

# of edge location > # availability zones > # of regions

identity access management 101
-------------------------------

iam allows you to manage users and the level of access to the aws console. 

- centralized control of your aws account
- shared access to your aws account
- granualar permissions
- identity federation (active directory, facebook etc.)
- multifactor authentication
- provides temporary access where necessary
- allows setting up password rotation policy
- integrates with many different aws services
- supports pci dss compliance

key terminology
- users
- groups
- policies (made of documents, and these documents are in json format)
- roles

7:13 AM 6/21/2019

what is the root account - this is the account that is used to sign up for aws. this has god mode access. 

- iam is universal. it does not apply to regions
- root account is the account created when setting up the aws account. it has complete admin access
- new users have no permissions when first created
	created an administrator access policy
	created developers group
- new users are assigned access key id and secret access key when first created
- different types of access - console access, programmatic access
- user access key id and secret keys are not the same as password. user access key id and secret keys cannot be used to access the console. they can be used to access aws via apis and command line
- always setup mfa on root account

s3 101
======

one of the oldest and most important services for the exam

s3 = simple storage service


- safe place to store files
- oject based storage i.e they can be uploaded & files can be between 0 - 5tb in size. 
- data is spread across multiple facilities
- buckets must be unique in name, because they exist in the global namespace
ex - https://s3-eu-west-1.amazonaws.com/<somename>
- when you upload a file to s3, an http 200 code is received
- objects consist of - key (name), value (data of the file), version id, metadata, sub resources (access control list, torrents)
- s3 buckets can be configured to create access logs and it can be sent to another bucket, even in a different account

how is data consistency achieved
- read after write consistency for PUTS and new objects. if you write a new file and read it immediately afterwards, you will be able to view that data. 
- eventual consistency for overwrite PUTS and DELETES (can take some time to propagate). if you update an existing file or delete a file and read it immediately, you may get the older version or maybe not. it might take some time to propagate the change. 

s3 - guarantees
- built for 99.99% availability for the s3 platform
- amazon will guarantee 99.9% availability
- amazon guarantees 99.99999999999% durability (99. eleven 9s)

s3 - features

- tiered storage (different storage classes)
- lifecycle management (moving between different tiers)
- versioning
- encryption
- mfa for deleting delete
- secure data using access control list and bucket policies
- stored redundant across multiple devices and multiple devices

5:46 AM Saturday, June 22, 2019

s3 storage classes

- s3 standard
	99.99% availability
	99. (eleven 9s) durability
	stored across multiple devices in multiple locations
	designed to sustain the loss of 2 facilities

s3 - ia (infrequently accessed)
	accessed less frequently and requires rapid access when accessed. charged retrieval fee

s3 one zone - ia
	low cost option for infrequently accessed data

s3 intelligent tiering
	uses machine learning to determine the tier, and moves it around different storage classes

s3 glacier
	secure low cost storage for data archiving
	retrieval times are configurable from minutes to hours

s3 glacier deep archive
	low cost storage where retrieval times of 12 hours is acceptable. this is the lowest cost of storage you can buy. 
	
s3 charges
	storage - the more you store in s3, the more you are charged
	requests - the more you request, the more you are charged
	storage management pricing - based on the tiers that are available
	data transfer pricing - 
	transfer acceleration - enable fast transfer of data between the end users and the s3 bucket. this takes advantage of amazon's cloudfront edge locations. as data arrives to the edge location, it is routed to amazon s3 over an optimized network path. 
	cross region replication pricing - if a bucket is in one region (us west) to another (sydney) and if cross region replication is turned on, then this data is replicated across these regions, and it costs to do so. 

exam tips for s3
	s3 is object based. i.e. it allows file upload
	files can be 0 bytes to 5TB
	there is unlimited storage
	files are stored in buckets (a folder in the cloud)
	buckets should have a unique name, they are in a universal namespace
	not suitable for installing an os or db
	successful upload will result in http 200 code
	you can turn on mfa delete
	key (name) - value (sequence of bytes; data) - version id - metadata - sub resources
	consistency model - read after write for puts of new objects; eventual consistency for overwrite puts and deletes (can take some time to propagate)
	rrs - reduced redundancy storage, which is an older synonym for ia (infrequently accessed)

s3 bucket properties that are most important for the solutions architect associate exam
	versioning
	static website hosting
	encryption
	transfer acceleration

12. s3 security and encryption
==============================
newly created buckets are private
access to the bucket can be controlled by
	bucket policies
	access control lists (acl)
s3 buckets can be configured to create access logs, these logs can be sent to another bucket, or another bucket in another account

there are different types of encryption
	encryption in transit. ex - accessing a website over https
		ssl/tls
	encryption at rest (server side), this can be achieved by -
		s3 managed keys - sse-s3 (server side encryption s3)
		aws key management service (kms), managed keys - sse-kms (server side encryption key management service)
		server side encryption with customer provided keys - sse-c
	client side encryption - encrypt the file client side, and upload it to s3

13. s3 version control
======================

Working with Delete Markers

A delete marker is a placeholder (marker) for a versioned object that was named in a simple DELETE request. Because the object was in a versioning-enabled bucket, the object was not deleted. The delete marker, however, makes Amazon S3 behave as if it had been deleted.

A delete marker has a key name (or key) and version ID like any other object. However, a delete marker differs from other objects in the following ways:

It does not have data associated with it.

It is not associated with an access control list (ACL) value.

It does not retrieve anything from a GET request because it has no data; you get a 404 error.

The only operation you can use on a delete marker is DELETE, and only the bucket owner can issue such a request.

Delete markers accrue a nominal charge for storage in Amazon S3. The storage size of a delete marker is equal to the size of the key name of the delete marker. A key name is a sequence of Unicode characters. The UTF-8 encoding adds from 1 to 4 bytes of storage to your bucket for each character in the name. For more information about key names, see Object Keys. For information about deleting a delete marker, see Removing Delete Markers.

Only Amazon S3 can create a delete marker, and it does so whenever you send a DELETE Object request on an object in a versioning-enabled or suspended bucket. The object named in the DELETE request is not actually deleted. Instead, the delete marker becomes the current version of the object. (The object's key name (or key) becomes the key of the delete marker.) If you try to get an object and its current version is a delete marker, Amazon S3 responds with:

A 404 (Object not found) error

A response header, x-amz-delete-marker: true

The response header tells you that the object accessed was a delete marker. This response header never returns false; if the value is false, Amazon S3 does not include this response header in the response.

The following figure shows how a simple GET on an object, whose current version is a delete marker, returns a 404 No Object Found error.

versioning
	stores all versions of an object, including all writes, even if the object is deleted
	once versioning is enabled, it can only be suspended. to disable versioning, the entire bucket has to be deleted.
	integrates with lifecycle rules
	versioning comes with mfa delete capability
	if a new version of the file is uploaded, it needs to be made public again. 
	the old versions are still available. 
	size of the s3 bucket is the sum of all the versions of the file(s)
	deleting a file will create a delete marker. deleting the delete marker will restore the file. 
	
14. lifecycle management with s3
================================

lifecycle rules manage objects by automating transition to tiered storage. 
can be used in conjunction with versioning. does not need versioning enabled.
it can be applied to current versions and previous versions


15. cross region replication
=============================

requires versioning to be enabled on both source and destination buckets
files in existing bucket are not automatically replicated. 
subsequent updates will be replicated
deletes in the "primary" bucket are not replicated in the replication-bucket. 
it is also not going to replicate deleting individual versions

16. transfer acceleration
=========================

s3 transfer acceleration utilizes the cloudfront edge network to accelerate uploads to s3

user will upload to an edge location first and then the amazon backbone network will upload it to an s3 bucket.

search for s3 transfer acceleration tool. this is the url that will compare the upload speeds - 
https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html

instead of uploading to an s3 bucket, you can upload directly to a distinct url that will then transfer the file to s3

17. cloudfront overview (Networking & Content Delivery)
=======================================================

key terminology
	edge location - this is a location where contact is cached. this is separate to an aws region/az
	origin - this is the origin of all the files that the cdn will distribute. s3 bucket, ec2 instance, elastic load balancer, route53
	distribution - name that is given to the cdn which consists of a collection of edge locations
	web distribution - typically used for websites
	rtmp - used for media streaming

cloudfront can be used to deliver your content (website - static/dynamic), steaming and interactive content using a global network of edge locations. request for the content are automatically routed to the nearest edge location so content is delivered as fast as possible

you can write to an edge location. 
objects are cached for the life of the ttl (time to live)
you can clear cached objects, but you will be charged

access to cloudfront distribution can be restricted using signed urls.

19. snowball
============

the primary use of snowball is to move large amount of data into the cloud. 

it is a petabyte scale data transport solution that uses secure appliances to transfer large amounts of data into and out of aws. 

transferring data with snowball is simple, fast, secure and can cost 1.5th of high speed internet

snowball edge comes in 100tb data transfer device with on-board storage and compute capabilities. 

snowball edge connects to your existing applications and infrastructure using standard storage interfaces. 

it can cluster together to form a local storage tier and process your data on premises, helping ensure your applications continue to run even when they are not able to access the cloud. 

snowball can import to s3, export to s3. 

20. storage gateway
===================

aws storage gateway is a service that connects an on-premises software appliance with cloud based storage to provide integration between an organization's on-premises IT environment and aws' storage infrastructure. 

aws' storage gateway software appliance is available for download as a virtual machine imagine that can be installed on a host in the datacenter. it support vmware, microsoft hyper-v. 

once installed, it is associated with the aws account through an activation process. after which the aws management console can be used to create the storage the right gateway option. 

there are three different types of storage gateway - 
	file gateway (NFS)
		stored as objects in s3 bucket accessed through network file system (nfs). once objects are stored in s3, they can be managed as native s3 objects. bucket policies apply. 
	volume gateway (imagine of a hard drive) (iscsi)
		stored volumes
			data written to these volumes can be asynchronously backed up as point-in-time snapshots of the volumes and stored in the cloud as amazon ebs snapshots. these snapshots are incremental backups. the images are also compressed.
		cached volumes
			these let you use s3 as primary data storage while retaining frequently accessed data locally in your storage gateway. 
			they minimize the need to scale on premises storage infrastructure while providing your applications with low-latency access to their frequently accessed data. 		
	tape gateway
		cost effective solution to archive your data. the vtl (virtual tape library) lets you leverage existing tape based backup application infrastructure to store data on virtual tape cartridges that you create on your tape gateway. each tape is preconfigured with a media changer and tape drivers, which are available you your existing client backup applications as iscsi devices. you add tape cartridges a you need to archive your data. supported by netbackup, backup exec, veeam etc. 

21. ec2 (compute) 101
=====================

pricing models
	on demand
		by the hour, by the second
	reserved
		this offers a significant discount on hourly rates. 
			standard reserved instances
			convertible reserved instances
			scheduled reserved instances
	spot
		enabled you to bid whatever price you want for instance capacity, providing for even greater savings
		application that have flexible start and end times
	dedicated houts
		physical ec2 server dedicated for your use.for steady state and steady usage
		for regulatory requirements, that may not support multi-tenent virtulization
		can be purchased on demand
		can be purchased as a reservation

to ensure that the web server is running at startup, type the following - chkconfig on
putty command for starting apache - sudo service httpd start

exam tips
---------

- termination protection is turned off by default
- on an ebs backed instance, the default action is for the root ebs volume to be deleted when instance is terminated
- ebs root volumes on your default ami's can be encrypted as of 2019. this is a new feature. 
- additional volumes can be encrypted


ec2 security groups
===================

- making changes to a security rule can take effect immediately. in other words, disabling port 80 in the security group would propagate the changes immediately.

- security group rules are stateful. this means if we are allowing traffic inbound to port 80, the outbound traffic over port 80 is automatically allowed. 

- there is no way to blacklist a particular port or an ip address via a security group

exam tips
---------

- all inbound traffic is blocked
- all outbound traffic is allowed
- changed to security groups take effect immediately
- you can have multiple security groups attached to a single instance
- you can have any number of ec2 instances within a security group
- security groups are stateful (no need to change inbound and outbound rules. if you allow inbound, outbound is allowed)
- cannot block specific ip addresses using security groups
- you can specify allow rules but not deny rules (can be done with network access controllers)

ebs (elastic block store) 101
=============================

the ebs volume is located in the same availability zone as the ec2 instance

standard - magnetic drive
sc1 - cold ssd
st1 - throughput optimized drive
gp2 - root volume

how to move volume from one availability zone to another?

- create a snapshot of the volume
- turn snapshot into an AMI
- create an instance using the AMI

- volumes exist in ebs. ebs is a virtual hard disk
- snapshots exist on s3
